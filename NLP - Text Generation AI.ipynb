{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48736216-1f87-4c17-8f48-ab9188f66ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 30.7/42.0 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 337.6 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 435.7 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.0/1.5 MB 393.8 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/1.5 MB 409.6 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/1.5 MB 409.6 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/1.5 MB 409.6 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/1.5 MB 409.6 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.5 MB 262.6 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.1/1.5 MB 285.2 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.5 MB 277.4 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.1/1.5 MB 277.4 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.1/1.5 MB 283.8 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.5 MB 283.8 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.5 MB 283.8 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 235.4 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 238.5 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 238.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 245.8 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 239.6 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 239.6 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 239.6 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 229.5 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/1.5 MB 241.9 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.3/1.5 MB 250.7 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.5 MB 250.7 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.5 MB 249.3 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.5 MB 249.3 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.5 MB 249.3 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.3/1.5 MB 234.6 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.3/1.5 MB 231.3 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.3/1.5 MB 231.3 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.3/1.5 MB 233.1 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 0.4/1.5 MB 242.3 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.4/1.5 MB 242.3 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.4/1.5 MB 242.3 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.4/1.5 MB 224.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 230.9 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 230.9 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 226.4 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 231.9 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 231.9 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 227.4 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 227.3 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 0.5/1.5 MB 234.0 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 0.5/1.5 MB 235.5 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.5/1.5 MB 248.3 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.5/1.5 MB 249.4 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.5/1.5 MB 249.4 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.6/1.5 MB 246.4 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.6/1.5 MB 245.8 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.6/1.5 MB 251.4 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 256.1 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 259.6 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 259.6 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 259.6 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.5 MB 249.3 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.5 MB 260.5 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.5 MB 260.5 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.5 MB 256.8 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.5 MB 259.9 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.5 MB 259.9 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.5 MB 259.9 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 0.7/1.5 MB 253.5 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 0.7/1.5 MB 253.7 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 0.7/1.5 MB 253.7 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 0.8/1.5 MB 253.9 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.8/1.5 MB 250.8 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.8/1.5 MB 250.8 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.8/1.5 MB 250.8 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.8/1.5 MB 247.4 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.8/1.5 MB 247.0 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.8/1.5 MB 249.7 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 252.3 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 251.8 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 251.8 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 251.8 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 249.4 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 249.4 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.5 MB 250.7 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.5 MB 253.1 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.5 MB 251.6 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.5 MB 251.6 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.5 MB 251.6 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.0/1.5 MB 250.4 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.0/1.5 MB 257.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.5 MB 258.5 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.5 MB 260.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.1/1.5 MB 261.1 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.1/1.5 MB 261.1 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 259.2 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 263.6 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.1/1.5 MB 268.0 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.2/1.5 MB 273.6 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.2/1.5 MB 277.8 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.2/1.5 MB 277.2 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.2/1.5 MB 277.2 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.2/1.5 MB 275.9 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.5 MB 280.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 288.3 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 288.3 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 288.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 284.0 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 284.0 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.5 MB 280.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 282.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 282.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 284.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 287.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 286.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 286.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.5 MB 284.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.5 MB 284.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 288.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 287.5 kB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/268.5 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/268.5 kB 660.6 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.5 kB 393.8 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/268.5 kB 508.4 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/268.5 kB 508.4 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/268.5 kB 508.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 92.2/268.5 kB 308.0 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 112.6/268.5 kB 312.2 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 122.9/268.5 kB 312.9 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 143.4/268.5 kB 340.5 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 163.8/268.5 kB 339.1 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 163.8/268.5 kB 339.1 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 163.8/268.5 kB 339.1 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 174.1/268.5 kB 283.5 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 194.6/268.5 kB 294.9 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 204.8/268.5 kB 289.5 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 225.3/268.5 kB 292.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/268.5 kB 301.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/268.5 kB 301.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/268.5 kB 301.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 268.5/268.5 kB 285.0 kB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/78.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 30.7/78.3 kB 445.2 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 41.0/78.3 kB 281.8 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 41.0/78.3 kB 281.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 71.7/78.3 kB 281.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.3/78.3 kB 290.7 kB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.5.15 tqdm-4.66.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "subset_text_df = text_df.sample(frac=0.001, random_state=42)  # Adjust the fraction as needed\n",
    "text = list(subset_text_df.text.values)\n",
    "joined_text = \" \".join(subset_text_df.text.values)\n",
    "\n",
    "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9765c588-4a77-4167-bba0-a4f8128c50d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd44a184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b15db14d-840a-4497-ba68-3c2eaf3c3092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ida\n",
      "0\n",
      "Anne\n",
      "1\n",
      "[['Ida', 'Anne'], ['Anne']]\n"
     ]
    }
   ],
   "source": [
    "students = [\"Ida\", \"Anne\"]\n",
    "for position,student in enumerate(students):\n",
    "    print(student)\n",
    "    print(position)\n",
    "ds = []\n",
    "for i in range(len(students)):\n",
    "    ds.append(students[i:i + 5])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b71531e-708f-47b1-aa6d-63bfd63db75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I\n",
      "1\n",
      "d\n",
      "2\n",
      "a\n",
      "0\n",
      "Ida\n",
      "0\n",
      "A\n",
      "1\n",
      "n\n",
      "2\n",
      "n\n",
      "3\n",
      "e\n",
      "1\n",
      "Anne\n"
     ]
    }
   ],
   "source": [
    "for position,student in enumerate(students):\n",
    "    for index, character in enumerate(student):\n",
    "        print(index)\n",
    "        print(character)\n",
    "    print(position)\n",
    "    print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b37da10-c72c-49a6-83b3-91ed9504689d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partial_text = joined_text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b351bd43-00b3-4421-b572-b633849b382c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_word = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_word.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
    "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)  # for each sample a boolean for each possible next word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "758caffb-288e-4c16-878d-f969fde3d081",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_word[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89102ca3-b2fe-4a34-97c2-666164405ae8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "54/54 [==============================] - 8s 74ms/step - loss: 6.7207 - accuracy: 0.0545\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 4s 82ms/step - loss: 6.4782 - accuracy: 0.0599\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 6.3959 - accuracy: 0.0698\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 4s 80ms/step - loss: 6.2955 - accuracy: 0.0757\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 5s 89ms/step - loss: 6.1325 - accuracy: 0.0854\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 5.9593 - accuracy: 0.0900\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 5.7533 - accuracy: 0.0978\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 5.5578 - accuracy: 0.1053\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 5.3488 - accuracy: 0.1118\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 5.1097 - accuracy: 0.1298\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X, y, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be143d5-2869-4676-b347-eb09da09a821",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 4.8376 - accuracy: 0.1526\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 4.5520 - accuracy: 0.1786\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 4.2457 - accuracy: 0.2101\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 3.9318 - accuracy: 0.2401\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 3.6150 - accuracy: 0.2862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, batch_size=128, epochs=5, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"text_gen_model2.h5\")\n",
    "with open(\"history2.p\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"text_gen_model2.h5\")\n",
    "history = pickle.load(open(\"history2.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 840ms/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"I will have to look into this thing because I\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "were\n",
      "now\n",
      "their\n",
      "because\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "for idx in possible:\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d8a2cb-90cc-4698-8418-76ec38384450",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "            print(\"Sorry, I didn't get that quiet well. Maybe you can contact our sales representative at someone'sname_sales@citybi.co.ke\")\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c868ebb-be16-4d4f-84df-196d983e09c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I will have to look into this thing because I own such there it it if to also by that to what about them there there the no market by an week there in a form with syria agents comey lives to be lives as said her have on is be for for its than on under clear is that is no only for like and all but it on what they were there by well the u s u but aristocracy t any controlled and the u of these other dunk having or not of an event on he are he are are history to his former about and'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"I will have to look into this thing because I\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1327b41d-3b8b-4064-8d9f-782a7a07417a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The president of the United States announced yesterday that he acts called federal establishment most t occasion 2008 it for it or get media america as be back but clinton or able for if one such that they might they have not as a federal market for the black market also an a market for information it that a no alter also against has than as lives and kill clinton after thus trump or well we been reported for an been between is to hillary a fbi up would simply to all that that have no been trump say to much but a no black against with there to be'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"The president of the United States announced yesterday that he\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd4036c-128d-4c4d-9d81-9584aa45b6b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "she\n",
      "an\n",
      "the\n",
      "no\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for idx in predict_next_word(\"The president will most likely not be there to \", 5):\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65d9b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'who is the kenyan president strictly 2 put urging are there they are is they a have'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"who is the kenyan president \", 12, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
